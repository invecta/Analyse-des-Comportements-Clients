{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Comportements Clients - Exploration des Donnees\n",
    "\n",
    "Ce notebook effectue une analyse exploratoire complete des donnees de comportement des clients.\n",
    "\n",
    "## Objectifs\n",
    "1. Charger et explorer les donnees clients\n",
    "2. Effectuer une evaluation de la qualite des donnees\n",
    "3. Creer des visualisations initiales\n",
    "4. Generer des statistiques de synthese\n",
    "5. Identifier des modeles et des insights\n",
    "\n",
    "## Table des Matieres\n",
    "1. [Configuration de l'Environnement](#configuration-de-lenvironnement)\n",
    "2. [Chargement des Donnees](#chargement-des-donnees)\n",
    "3. [Apercu des Donnees](#apercu-des-donnees)\n",
    "4. [Evaluation de la Qualite des Donnees](#evaluation-de-la-qualite-des-donnees)\n",
    "5. [Visualisations Exploratoires](#visualisations-exploratoires)\n",
    "6. [Statistiques de Synthese](#statistiques-de-synthese)\n",
    "7. [Insights Cles](#insights-cles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration de l'Environnement\n",
    "\n",
    "Commencons par importer toutes les bibliotheques necessaires pour l'analyse de donnees et la visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliotheques necessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import random\n",
    "\n",
    "# Configuration du style de graphiques\n",
    "plt.style.use('default')  # Change de 'seaborn-v0_8' vers 'default' pour la compatibilite\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des options d'affichage\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"Bibliotheques importees avec succes!\")\n",
    "print(f\"Version Pandas: {pd.__version__}\")\n",
    "print(f\"Version NumPy: {np.__version__}\")\n",
    "print(f\"Version Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"Version Seaborn: {sns.__version__}\")\n",
    "\n",
    "# Fonctions de generation de donnees (integrees pour eviter les problemes d'import)\n",
    "def get_sample_data(n_customers: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"Generer des donnees d'exemple de comportement client pour l'analyse.\"\"\"\n",
    "    np.random.seed(42)  # Pour des resultats reproductibles\n",
    "    random.seed(42)\n",
    "    \n",
    "    # Generer les IDs clients\n",
    "    customer_ids = [f\"CUST_{i:04d}\" for i in range(1, n_customers + 1)]\n",
    "    \n",
    "    # Generer les donnees demographiques\n",
    "    ages = np.random.normal(45, 15, n_customers).astype(int)\n",
    "    ages = np.clip(ages, 18, 80)  # Assurer une plage d'age raisonnable\n",
    "    \n",
    "    genders = np.random.choice(['M', 'F', 'Other'], n_customers, p=[0.4, 0.5, 0.1])\n",
    "    \n",
    "    cities = np.random.choice([\n",
    "        'Zurich', 'Geneva', 'Basel', 'Bern', 'Lausanne', 'Lucerne'\n",
    "    ], n_customers)\n",
    "    \n",
    "    # Generer les dates d'inscription (reparties sur 2023)\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    end_date = datetime(2023, 12, 31)\n",
    "    date_range = (end_date - start_date).days\n",
    "    \n",
    "    registration_dates = [\n",
    "        start_date + timedelta(days=random.randint(0, date_range))\n",
    "        for _ in range(n_customers)\n",
    "    ]\n",
    "    \n",
    "    # Generer les donnees comportementales avec des correlations realistes\n",
    "    # Age plus eleve -> depenses legerement plus elevees\n",
    "    age_factor = (ages - ages.mean()) / ages.std()\n",
    "    \n",
    "    # Generer le nombre total d'achats (1-20, avec une correlation a l'age)\n",
    "    total_purchases = np.random.poisson(5, n_customers) + np.random.poisson(2, n_customers) * (1 + 0.1 * age_factor)\n",
    "    total_purchases = np.clip(total_purchases, 1, 20).astype(int)\n",
    "    \n",
    "    # Generer le montant total depense (correle avec les achats et l'age)\n",
    "    base_spending = 50 + 30 * total_purchases + 2 * ages + np.random.normal(0, 50, n_customers)\n",
    "    total_spent = np.maximum(base_spending, 0.5)  # Minimum 0.50$\n",
    "    \n",
    "    # Generer les donnees de session\n",
    "    avg_session_duration = np.random.exponential(10, n_customers) + 5\n",
    "    avg_session_duration = np.clip(avg_session_duration, 0.5, 35)\n",
    "    \n",
    "    page_views_per_session = np.random.poisson(8, n_customers) + np.random.poisson(3, n_customers)\n",
    "    page_views_per_session = np.clip(page_views_per_session, 2, 25).astype(int)\n",
    "    \n",
    "    # Taux de rebond (relation inverse avec la duree de session)\n",
    "    bounce_rate = np.random.beta(2, 5, n_customers) * (1 - 0.3 * (avg_session_duration / avg_session_duration.max()))\n",
    "    bounce_rate = np.clip(bounce_rate, 0.01, 0.8)\n",
    "    \n",
    "    # Generer les dates de derniere activite (apres inscription, dans une plage raisonnable)\n",
    "    last_activity_dates = []\n",
    "    for reg_date in registration_dates:\n",
    "        # Derniere activite entre l'inscription et la fin de 2023\n",
    "        days_after_reg = random.randint(0, (end_date - reg_date).days)\n",
    "        last_activity_dates.append(reg_date + timedelta(days=days_after_reg))\n",
    "    \n",
    "    # Generer les types d'abonnement (correles avec les depenses)\n",
    "    # Utiliser les quantiles pour creer des types d'abonnement bases sur les depenses\n",
    "    q25 = np.percentile(total_spent, 25)\n",
    "    q50 = np.percentile(total_spent, 50)\n",
    "    q75 = np.percentile(total_spent, 75)\n",
    "    \n",
    "    subscription_types = []\n",
    "    for spending in total_spent:\n",
    "        if spending <= q25:\n",
    "            subscription_types.append('Basic')\n",
    "        elif spending <= q50:\n",
    "            subscription_types.append(np.random.choice(['Basic', 'Premium'], p=[0.4, 0.6]))\n",
    "        elif spending <= q75:\n",
    "            subscription_types.append(np.random.choice(['Premium', 'Enterprise'], p=[0.7, 0.3]))\n",
    "        else:  # Top 25%\n",
    "            subscription_types.append(np.random.choice(['Premium', 'Enterprise'], p=[0.3, 0.7]))\n",
    "    \n",
    "    # Generer les types d'appareils\n",
    "    device_types = np.random.choice(['Mobile', 'Desktop', 'Tablet'], n_customers, p=[0.6, 0.3, 0.1])\n",
    "    \n",
    "    # Generer les scores de satisfaction (quelques valeurs manquantes, correles avec les depenses)\n",
    "    satisfaction_scores = []\n",
    "    for i in range(n_customers):\n",
    "        if random.random() < 0.05:  # 5% de valeurs manquantes\n",
    "            satisfaction_scores.append(np.nan)\n",
    "        else:\n",
    "            # Depenses plus elevees -> satisfaction legerement plus elevee\n",
    "            base_satisfaction = 5 + 0.5 * (total_spent[i] / total_spent.max()) + np.random.normal(0, 1.5)\n",
    "            satisfaction_scores.append(np.clip(base_satisfaction, 1, 10))\n",
    "    \n",
    "    # Generer les tickets de support (correles avec les achats et la satisfaction)\n",
    "    support_tickets = []\n",
    "    for i in range(n_customers):\n",
    "        base_tickets = np.random.poisson(1)\n",
    "        # Plus d'achats -> plus de tickets, satisfaction plus faible -> plus de tickets\n",
    "        if not np.isnan(satisfaction_scores[i]):\n",
    "            satisfaction_factor = max(0, 6 - satisfaction_scores[i]) / 5\n",
    "        else:\n",
    "            satisfaction_factor = 0.5\n",
    "        tickets = base_tickets + int(total_purchases[i] * 0.1) + int(satisfaction_factor * 2)\n",
    "        support_tickets.append(max(0, min(tickets, 8)))  # Max 8 tickets, min 0\n",
    "    \n",
    "    # Generer les sources de reference\n",
    "    referral_sources = np.random.choice([\n",
    "        'Organic', 'Social Media', 'Email', 'Paid Ads', 'Referral'\n",
    "    ], n_customers, p=[0.3, 0.25, 0.2, 0.15, 0.1])\n",
    "    \n",
    "    # Creer le DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'customer_id': customer_ids,\n",
    "        'age': ages,\n",
    "        'gender': genders,\n",
    "        'city': cities,\n",
    "        'registration_date': registration_dates,\n",
    "        'total_purchases': total_purchases,\n",
    "        'total_spent': total_spent,\n",
    "        'avg_session_duration': avg_session_duration,\n",
    "        'page_views_per_session': page_views_per_session,\n",
    "        'bounce_rate': bounce_rate,\n",
    "        'last_activity': last_activity_dates,\n",
    "        'subscription_type': subscription_types,\n",
    "        'device_type': device_types,\n",
    "        'satisfaction_score': satisfaction_scores,\n",
    "        'support_tickets': support_tickets,\n",
    "        'referral_source': referral_sources\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def validate_customer_data(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Valider les donnees clients pour la qualite et la completude.\"\"\"\n",
    "    validation_results = {\n",
    "        'total_rows': len(df),\n",
    "        'total_columns': len(df.columns),\n",
    "        'missing_values': df.isnull().sum().sum(),\n",
    "        'duplicate_rows': df.duplicated().sum(),\n",
    "        'data_types': df.dtypes.to_dict(),\n",
    "        'column_names': list(df.columns),\n",
    "        'validation_passed': True,\n",
    "        'issues': []\n",
    "    }\n",
    "    \n",
    "    # Verifier les IDs clients dupliques\n",
    "    if 'customer_id' in df.columns:\n",
    "        duplicate_ids = df['customer_id'].duplicated().sum()\n",
    "        if duplicate_ids > 0:\n",
    "            validation_results['issues'].append(f\"Trouve {duplicate_ids} IDs clients dupliques\")\n",
    "            validation_results['validation_passed'] = False\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "print(\"Fonctions de generation de donnees definies avec succes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Donnees\n",
    "\n",
    "Creons des donnees d'exemple de comportement client pour travailler. Dans un scenario reel, vous chargeriez votre jeu de donnees reel ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des donnees d'exemple de comportement client en utilisant le module de collecte de donnees\n",
    "n_customers = 1000\n",
    "\n",
    "# Utiliser le module de collecte de donnees pour generer des donnees d'exemple\n",
    "df = get_sample_data(n_customers)\n",
    "\n",
    "# Valider les donnees generees\n",
    "validation_results = validate_customer_data(df)\n",
    "\n",
    "print(\"Donnees d'exemple de comportement client creees avec succes!\")\n",
    "print(f\"Forme du jeu de donnees: {df.shape}\")\n",
    "print(f\"Plage de dates: {df['registration_date'].min().strftime('%Y-%m-%d')} a {df['registration_date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Validation des donnees: {validation_results['total_rows']} lignes, {validation_results['total_columns']} colonnes\")\n",
    "print(f\"Valeurs manquantes: {validation_results['missing_values']}\")\n",
    "print(f\"Lignes dupliquees: {validation_results['duplicate_rows']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apercu des Donnees\n",
    "\n",
    "Obtenons un apercu complet de la structure et du contenu de notre jeu de donnees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les informations de base sur le jeu de donnees\n",
    "print(\"=\" * 60)\n",
    "print(\"APERCU DU JEU DE DONNEES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Forme du jeu de donnees: {df.shape[0]:,} lignes x {df.shape[1]} colonnes\")\n",
    "print(f\"Utilisation de la memoire: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print()\n",
    "\n",
    "# Afficher les informations sur les colonnes\n",
    "print(\"INFORMATIONS SUR LES COLONNES\")\n",
    "print(\"-\" * 40)\n",
    "print(df.info())\n",
    "print()\n",
    "\n",
    "# Afficher les premieres lignes\n",
    "print(\"PREMIERES 5 LIGNES\")\n",
    "print(\"-\" * 40)\n",
    "display(df.head())\n",
    "print()\n",
    "\n",
    "# Afficher les dernieres lignes\n",
    "print(\"DERNIERES 5 LIGNES\")\n",
    "print(\"-\" * 40)\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de la Qualite des Donnees\n",
    "\n",
    "Evaluation complete de la qualite des donnees incluant les valeurs manquantes, les doublons, les valeurs aberrantes et les verifications de coherence des donnees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Analyse des Valeurs Manquantes\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYSE DES VALEURS MANQUANTES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculer les valeurs manquantes\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "\n",
    "# Creer un resume des valeurs manquantes\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Colonne': missing_data.index,\n",
    "    'Nombre de Valeurs Manquantes': missing_data.values,\n",
    "    'Pourcentage de Valeurs Manquantes': missing_percentage.values\n",
    "}).sort_values('Nombre de Valeurs Manquantes', ascending=False)\n",
    "\n",
    "# Filtrer pour afficher seulement les colonnes avec des valeurs manquantes\n",
    "missing_summary = missing_summary[missing_summary['Nombre de Valeurs Manquantes'] > 0]\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    print(\"Colonnes avec des valeurs manquantes:\")\n",
    "    display(missing_summary)\n",
    "    \n",
    "    # Visualiser les valeurs manquantes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    missing_data[missing_data > 0].plot(kind='bar', color='salmon')\n",
    "    plt.title('Nombre de Valeurs Manquantes par Colonne')\n",
    "    plt.xlabel('Colonnes')\n",
    "    plt.ylabel('Nombre de Valeurs Manquantes')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    missing_percentage[missing_percentage > 0].plot(kind='bar', color='lightcoral')\n",
    "    plt.title('Pourcentage de Valeurs Manquantes par Colonne')\n",
    "    plt.xlabel('Colonnes')\n",
    "    plt.ylabel('Pourcentage de Valeurs Manquantes (%)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucune valeur manquante trouvee dans le jeu de donnees!\")\n",
    "    print(\"Completude des donnees: 100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations Exploratoires\n",
    "\n",
    "Creer des visualisations completes pour comprendre les distributions de donnees, les relations et les modeles dans le comportement des clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Analyse de Distribution - Variables Numeriques\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYSE DE DISTRIBUTION - VARIABLES NUMERIQUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Selectionner les variables numeriques cles pour l'analyse de distribution\n",
    "numeric_vars = ['age', 'total_purchases', 'total_spent', 'avg_session_duration', \n",
    "                'page_views_per_session', 'bounce_rate', 'satisfaction_score', 'support_tickets']\n",
    "\n",
    "# Filtrer pour inclure seulement les colonnes qui existent dans le dataframe\n",
    "numeric_vars = [var for var in numeric_vars if var in df.columns]\n",
    "\n",
    "# Creer des graphiques de distribution\n",
    "n_vars = len(numeric_vars)\n",
    "n_cols = min(4, n_vars)\n",
    "n_rows = (n_vars + n_cols - 1) // n_cols  # Division par le plafond\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "if n_vars == 1:\n",
    "    axes = [axes]\n",
    "elif n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, var in enumerate(numeric_vars):\n",
    "    if i < len(axes):\n",
    "        # Histogramme\n",
    "        df[var].hist(bins=30, alpha=0.7, ax=axes[i], color='skyblue', edgecolor='black')\n",
    "        \n",
    "        # Ajouter les statistiques\n",
    "        mean_val = df[var].mean()\n",
    "        median_val = df[var].median()\n",
    "        axes[i].axvline(mean_val, color='green', linestyle='--', linewidth=2, label=f'Moyenne: {mean_val:.2f}')\n",
    "        axes[i].axvline(median_val, color='orange', linestyle='--', linewidth=2, label=f'Mediane: {median_val:.2f}')\n",
    "        \n",
    "        axes[i].set_title(f'Distribution de {var}', fontsize=12, fontweight='bold')\n",
    "        axes[i].set_xlabel(var)\n",
    "        axes[i].set_ylabel('Frequence')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Masquer les sous-graphiques non utilises\n",
    "for i in range(n_vars, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques de synthese pour les distributions\n",
    "print(\"\\nSTATISTIQUES DE SYNTHESE DES DISTRIBUTIONS:\")\n",
    "print(\"-\" * 50)\n",
    "distribution_stats = df[numeric_vars].describe()\n",
    "display(distribution_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistiques de Synthese\n",
    "\n",
    "Statistiques de synthese completes, metriques commerciales et insights cles de l'analyse du comportement des clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Statistiques de Synthese Executives\n",
    "print(\"=\" * 80)\n",
    "print(\"STATISTIQUES DE SYNTHESE EXECUTIVES - ANALYSE DES COMPORTEMENTS CLIENTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Metriques Commerciales Cles\n",
    "total_customers = len(df)\n",
    "total_revenue = df['total_spent'].sum() if 'total_spent' in df.columns else 0\n",
    "avg_revenue_per_customer = df['total_spent'].mean() if 'total_spent' in df.columns else 0\n",
    "median_revenue_per_customer = df['total_spent'].median() if 'total_spent' in df.columns else 0\n",
    "total_purchases = df['total_purchases'].sum() if 'total_purchases' in df.columns else 0\n",
    "avg_purchases_per_customer = df['total_purchases'].mean() if 'total_purchases' in df.columns else 0\n",
    "avg_satisfaction = df['satisfaction_score'].mean() if 'satisfaction_score' in df.columns else 0\n",
    "avg_session_duration = df['avg_session_duration'].mean() if 'avg_session_duration' in df.columns else 0\n",
    "\n",
    "print(f\"Total Clients: {total_customers:,}\")\n",
    "print(f\"Chiffre d'Affaires Total: ${total_revenue:,.2f}\")\n",
    "print(f\"Chiffre d'Affaires Moyen par Client: ${avg_revenue_per_customer:.2f}\")\n",
    "print(f\"Chiffre d'Affaires Median par Client: ${median_revenue_per_customer:.2f}\")\n",
    "print(f\"Total Achats: {total_purchases:,}\")\n",
    "print(f\"Achats Moyens par Client: {avg_purchases_per_customer:.1f}\")\n",
    "print(f\"Score de Satisfaction Moyen: {avg_satisfaction:.1f}/10\")\n",
    "print(f\"Duree Moyenne de Session: {avg_session_duration:.1f} minutes\")\n",
    "print()\n",
    "\n",
    "# Resume Demographique des Clients\n",
    "print(\"DEMOGRAPHIE DES CLIENTS:\")\n",
    "print(\"-\" * 40)\n",
    "if 'age' in df.columns:\n",
    "    print(f\"Age Moyen: {df['age'].mean():.1f} ans\")\n",
    "    print(f\"Plage d'Age: {df['age'].min()} - {df['age'].max()} ans\")\n",
    "else:\n",
    "    print(\"Donnees d'age non disponibles\")\n",
    "\n",
    "if 'gender' in df.columns:\n",
    "    print(f\"Repartition par Genre:\")\n",
    "    gender_dist = df['gender'].value_counts()\n",
    "    for gender, count in gender_dist.items():\n",
    "        percentage = (count / total_customers) * 100\n",
    "        print(f\"  {gender}: {count} ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"Donnees de genre non disponibles\")\n",
    "\n",
    "if 'city' in df.columns:\n",
    "    print(f\"\\nTop 3 Villes par Nombre de Clients:\")\n",
    "    city_dist = df['city'].value_counts().head(3)\n",
    "    for city, count in city_dist.items():\n",
    "        percentage = (count / total_customers) * 100\n",
    "        print(f\"  {city}: {count} ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"Donnees de ville non disponibles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights Cles et Recommandations Commerciales\n",
    "\n",
    "Insights cles et recommandations strategiques basees sur l'analyse des donnees de comportement des clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights et Recommandations Commerciales\n",
    "print(\"=\" * 80)\n",
    "print(\"INSIGHTS CLES ET RECOMMANDATIONS COMMERCIALES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Insights sur le comportement des clients\n",
    "print(\"INSIGHTS SUR LE COMPORTEMENT DES CLIENTS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Comportement de depenses\n",
    "high_spenders = df[df['total_spent'] > df['total_spent'].quantile(0.75)]\n",
    "low_spenders = df[df['total_spent'] < df['total_spent'].quantile(0.25)]\n",
    "\n",
    "print(f\"â€¢ Gros Depensiers (Top 25%) vs Petits Depensiers (Bottom 25%):\")\n",
    "print(f\"  - Gros Depensiers: {len(high_spenders)} clients, Moyenne: ${high_spenders['total_spent'].mean():.2f}\")\n",
    "print(f\"  - Petits Depensiers: {len(low_spenders)} clients, Moyenne: ${low_spenders['total_spent'].mean():.2f}\")\n",
    "print(f\"  - Ratio de Depenses: {high_spenders['total_spent'].mean() / low_spenders['total_spent'].mean():.1f}x\")\n",
    "\n",
    "# Modeles d'engagement\n",
    "print(f\"\\nâ€¢ Modeles d'Engagement:\")\n",
    "print(f\"  - Engagement Eleve (Sessions Longues): {len(df[df['avg_session_duration'] > df['avg_session_duration'].quantile(0.75)])} clients\")\n",
    "print(f\"  - Engagement Faible (Sessions Courtes): {len(df[df['avg_session_duration'] < df['avg_session_duration'].quantile(0.25)])} clients\")\n",
    "print(f\"  - Taux de Rebond Eleve (>50%): {len(df[df['bounce_rate'] > 0.5])} clients ({len(df[df['bounce_rate'] > 0.5])/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Analyse de satisfaction\n",
    "print(f\"\\nâ€¢ Analyse de Satisfaction:\")\n",
    "satisfied_customers = df[df['satisfaction_score'] >= 8]\n",
    "dissatisfied_customers = df[df['satisfaction_score'] <= 4]\n",
    "print(f\"  - Clients Satisfaits (8+): {len(satisfied_customers)} ({len(satisfied_customers)/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Clients Insatisfaits (â‰¤4): {len(dissatisfied_customers)} ({len(dissatisfied_customers)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Recommandations Commerciales\n",
    "print(f\"\\nRECOMMANDATIONS STRATEGIQUES:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Optimisation des revenus\n",
    "print(\"OPTIMISATION DES REVENUS:\")\n",
    "print(\"1. Se concentrer sur les Segments Clients a Haute Valeur:\")\n",
    "if 'subscription_type' in df.columns:\n",
    "    best_subscription = df.groupby('subscription_type')['total_spent'].mean().idxmax()\n",
    "    print(f\"   â€¢ Cibler les clients avec abonnements {best_subscription}\")\n",
    "if 'device_type' in df.columns:\n",
    "    best_device = df.groupby('device_type')['total_spent'].mean().idxmax()\n",
    "    print(f\"   â€¢ Prioriser les utilisateurs {best_device} pour les fonctionnalites premium\")\n",
    "\n",
    "# Strategie d'abonnement\n",
    "print(f\"\\n2. Strategie d'Abonnement:\")\n",
    "if 'subscription_type' in df.columns:\n",
    "    print(f\"   â€¢ Promouvoir l'abonnement {best_subscription} car il montre les depenses moyennes les plus elevees\")\n",
    "    print(f\"   â€¢ Creer des incitations a la mise a niveau pour les clients Basic â†’ Premium\")\n",
    "\n",
    "# Expansion geographique\n",
    "print(f\"\\n3. Expansion Geographique:\")\n",
    "if 'city' in df.columns:\n",
    "    top_city = df.groupby('city')['total_spent'].mean().idxmax()\n",
    "    print(f\"   â€¢ Etendre les efforts marketing a {top_city} (depenses moyennes les plus elevees)\")\n",
    "    print(f\"   â€¢ Repliquer les strategies reussies des villes les plus performantes\")\n",
    "\n",
    "# Experience client\n",
    "print(f\"\\n4. Ameliorations de l'Experience Client:\")\n",
    "print(f\"   â€¢ Adresser le taux de rebond eleve ({len(df[df['bounce_rate'] > 0.5])/len(df)*100:.1f}% des clients)\")\n",
    "print(f\"   â€¢ Ameliorer la duree de session pour un meilleur engagement\")\n",
    "print(f\"   â€¢ Implementer des enquetes de satisfaction pour les clients notes â‰¤4\")\n",
    "\n",
    "print(f\"\\nMETRIQUES DE SUCCES A SUIVRE:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"â€¢ Valeur Vie Client (CLV)\")\n",
    "print(\"â€¢ Revenus Recurrents Mensuels (MRR)\")\n",
    "print(\"â€¢ Cout d'Acquisition Client (CAC)\")\n",
    "print(\"â€¢ Taux de Desabonnement par segment\")\n",
    "print(\"â€¢ Score Net Promoter (NPS)\")\n",
    "print(\"â€¢ Revenus Moyens par Utilisateur (ARPU)\")\n",
    "\n",
    "print(\"\\nANALYSE EXPLORATOIRE TERMINEE!\")\n",
    "print(\"Votre analyse complete du comportement des clients est prete!\")\n",
    "print(\"Utilisez ces insights pour orienter les decisions commerciales basees sur les donnees!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

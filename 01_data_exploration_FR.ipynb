{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Comportements Clients - Exploration des Donnees\n",
    "\n",
    "Ce notebook effectue une analyse exploraaire complete des donnees de comportement des clients.\n",
    "\n",
    "## Objectifs\n",
    "1. Charger et explorer les donnees clients\n",
    "2. Effectuer une evaluation de la qualite des donnees\n",
    "3. Creer des visualisations initiales\n",
    "4. Generer des statistiques de synthese\n",
    "5. Identifier des modeles et des insights\n",
    "\n",
    "## Table des Matieres\n",
    "1. [Configuration de l'Environnement](#configuration-de-lenvironnement)\n",
    "2. [Chargement des Donnees](#chargement-des-donnees)\n",
    "3. [Apercu des Donnees](#apercu-des-donnees)\n",
    "4. [Evaluation de la Qualite des Donnees](#evaluation-de-la-qualite-des-donnees)\n",
    "5. [Visualisations Exploraaires](#visualisations-exploraaires)\n",
    "6. [Statistiques de Synthese](#statistiques-de-synthese)\n",
    "7. [Insights Cles](#insights-cles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration de l'Environnement\n",
    "\n",
    "Commencons par importer autes les bibliotheques necessaires pour l'analyse de donnees et la visualisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliotheques necessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matgraphiquelib.pygraphique as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import graphiquely.express as px\n",
    "import graphiquely.graph_objets as go\n",
    "from graphiquely.subgraphiques import make_subgraphiques\n",
    "import random\n",
    "\n",
    "# Configuration du style de graphiques\n",
    "plt.style.use('default')  # Change de 'seaborn-v0_8' vers 'default' pour la compatibilite\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des options d'affichage\n",
    "pd.set_option('display.max_colonnes', None)\n",
    "pd.set_option('display.largeur', None)\n",
    "pd.set_option('display.max_collargeur', 50)\n",
    "\n",
    "print(\"✅ Bibliotheques importees avec succes!\")\n",
    "print(f\"📊 Pandas version: {pd.__version__}\")\n",
    "print(f\"🔢 NumPy version: {np.__version__}\")\n",
    "print(f\"📈 Matgraphiquelib version: {plt.matgraphiquelib.__version__}\")\n",
    "print(f\"🎨 Seaborn version: {sns.__version__}\")\n",
    "\n",
    "# Fonctions de generation de donnees (integrees pour eviter les problemes d'import)\n",
    "def get_donnees_echantillon(n_clients: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"Generate sample cusamer behavior donnees for analyse.\"\"\"\n",
    "    np.random.seed(42)  # Pour des resultatats reproductibles\n",
    "    random.seed(42)\n",
    "    \n",
    "    # Generer les IDs clients\n",
    "    ids_clients = [f\"CUST_{i:04d}\" for i in range(1, n_clients + 1)]\n",
    "    \n",
    "    # Generer les donnees demographiques\n",
    "    ages = np.random.normal(45, 15, n_clients).astype(int)\n",
    "    ages = np.clip(ages, 18, 80)  # Assurer une plage d'age raisonnable\n",
    "    \n",
    "    genres = np.random.choice(['M', 'F', 'Other'], n_clients, p=[0.4, 0.5, 0.1])\n",
    "    \n",
    "    villes = np.random.choice([\n",
    "        'Zurich', 'Geneva', 'Basel', 'Bern', 'Lausanne', 'Lucerne'\n",
    "    ], n_clients)\n",
    "    \n",
    "    # Generer les dates d'inscription (reparties sur 2023)\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    end_date = datetime(2023, 12, 31)\n",
    "    date_range = (end_date - start_date).days\n",
    "    \n",
    "    dates_inscription = [\n",
    "        start_date + timedelta(days=random.randint(0, date_range))\n",
    "        for _ in range(n_clients)\n",
    "    ]\n",
    "    \n",
    "    # Generer les donnees comportementales avec des correlations realistes\n",
    "    # Age plus eleve -> depenses legerement plus elevees\n",
    "    age_facar = (ages - ages.mean()) / ages.std()\n",
    "    \n",
    "    # Generer le nombre atal d'achats (1-20, avec une correlation a l'age)\n",
    "    atal_achats = np.random.poisson(5, n_clients) + np.random.poisson(2, n_clients) * (1 + 0.1 * age_facar)\n",
    "    atal_achats = np.clip(atal_achats, 1, 20).astype(int)\n",
    "    \n",
    "    # Generer le montant atal depense (correle avec les achats et l'age)\n",
    "    base_spending = 50 + 30 * atal_achats + 2 * ages + np.random.normal(0, 50, n_clients)\n",
    "    atal_depense = np.maximum(base_spending, 0.5)  # Minimum 0.50CHF\n",
    "    \n",
    "    # Generer les donnees de session\n",
    "    duree_moyenne_session = np.random.exponential(10, n_clients) + 5\n",
    "    duree_moyenne_session = np.clip(duree_moyenne_session, 0.5, 35)\n",
    "    \n",
    "    vues_page_par_session = np.random.poisson(8, n_clients) + np.random.poisson(3, n_clients)\n",
    "    vues_page_par_session = np.clip(vues_page_par_session, 2, 25).astype(int)\n",
    "    \n",
    "    # Taux de rebond (relation inverse avec la duree de session)\n",
    "    taux_rebond = np.random.beta(2, 5, n_clients) * (1 - 0.3 * (duree_moyenne_session / duree_moyenne_session.max()))\n",
    "    taux_rebond = np.clip(taux_rebond, 0.01, 0.8)\n",
    "    \n",
    "    # Generer les dates de derniere activite (apres inscription, dans une plage raisonnable)\n",
    "    dates_derniere_activite = []\n",
    "    for reg_date in dates_inscription:\n",
    "        # Derniere activite entre l'inscription et la fin de 2023\n",
    "        days_after_reg = random.randint(0, (end_date - reg_date).days)\n",
    "        dates_derniere_activite.append(reg_date + timedelta(days=days_after_reg))\n",
    "    \n",
    "    # Generer les types d'abonnement (correles avec les depenses)\n",
    "    # Utiliser les quantiles pour creer des types d'abonnement bases sur les depenses\n",
    "    q25 = np.percentile(atal_depense, 25)\n",
    "    q50 = np.percentile(atal_depense, 50)\n",
    "    q75 = np.percentile(atal_depense, 75)\n",
    "    \n",
    "    types_abonnement = []\n",
    "    for spending in atal_depense:\n",
    "        if spending <= q25:\n",
    "            types_abonnement.append('Basique')\n",
    "        elif spending <= q50:\n",
    "            types_abonnement.append(np.random.choice(['Basique', 'Premium'], p=[0.4, 0.6]))\n",
    "        elif spending <= q75:\n",
    "            types_abonnement.append(np.random.choice(['Premium', 'Entreprise'], p=[0.7, 0.3]))\n",
    "        else:  # Top 25%\n",
    "            types_abonnement.append(np.random.choice(['Premium', 'Entreprise'], p=[0.3, 0.7]))\n",
    "    \n",
    "    # Generer les types d'appareils\n",
    "    types_appareil = np.random.choice(['Mobile', 'Bureau', 'Tablette'], n_clients, p=[0.6, 0.3, 0.1])\n",
    "    \n",
    "    # Generer les scores de satisfaction (quelques valeurs manquantes, correles avec les depenses)\n",
    "    score_satisfactions = []\n",
    "    for i in range(n_clients):\n",
    "        if random.random() < 0.05:  # 5% de valeurs manquantes\n",
    "            score_satisfactions.append(np.nan)\n",
    "        else:\n",
    "            # Depenses plus elevees -> satisfaction legerement plus elevee\n",
    "            base_satisfaction = 5 + 0.5 * (atal_depense[i] / atal_depense.max()) + np.random.normal(0, 1.5)\n",
    "            score_satisfactions.append(np.clip(base_satisfaction, 1, 10))\n",
    "    \n",
    "    # Generer les tickets de support (correles avec les achats et la satisfaction)\n",
    "    tickets_support = []\n",
    "    for i in range(n_clients):\n",
    "        base_tickets = np.random.poisson(1)\n",
    "        # Plus d'achats -> plus de tickets, satisfaction plus faible -> plus de tickets\n",
    "        if not np.isnan(score_satisfactions[i]):\n",
    "            satisfaction_facar = max(0, 6 - score_satisfactions[i]) / 5\n",
    "        else:\n",
    "            satisfaction_facar = 0.5\n",
    "        tickets = base_tickets + int(atal_achats[i] * 0.1) + int(satisfaction_facar * 2)\n",
    "        tickets_support.append(max(0, min(tickets, 8)))  # Max 8 tickets, min 0\n",
    "    \n",
    "    # Generer les sources de reference\n",
    "    sources_reference = np.random.choice([\n",
    "        'Organique', 'Social Media', 'Email', 'Paye Ads', 'Reference'\n",
    "    ], n_clients, p=[0.3, 0.25, 0.2, 0.15, 0.1])\n",
    "    \n",
    "    # Creer le DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'id_client': ids_clients,\n",
    "        'age': ages,\n",
    "        'genre': genres,\n",
    "        'ville': villes,\n",
    "        'date_inscription': dates_inscription,\n",
    "        'atal_achats': atal_achats,\n",
    "        'atal_depense': atal_depense,\n",
    "        'duree_moyenne_session': duree_moyenne_session,\n",
    "        'vues_page_par_session': vues_page_par_session,\n",
    "        'taux_rebond': taux_rebond,\n",
    "        'derniere_activite': dates_derniere_activite,\n",
    "        'type_abonnement': types_abonnement,\n",
    "        'type_appareil': types_appareil,\n",
    "        'score_satisfaction': score_satisfactions,\n",
    "        'tickets_support': tickets_support,\n",
    "        'source_reference': sources_reference\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def validate_donnees_client(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Validate the cusamer donnees for qualite and completeness.\"\"\"\n",
    "    validation_resultats = {\n",
    "        'atal_lignes': len(df),\n",
    "        'atal_colonnes': len(df.colonnes),\n",
    "        'manquantes_values': df.isnull().sum().sum(),\n",
    "        'duplicate_lignes': df.duplicated().sum(),\n",
    "        'donnees_types': df.types.a_dict(),\n",
    "        'column_names': list(df.colonnes),\n",
    "        'validation_passed': True,\n",
    "        'issues': []\n",
    "    }\n",
    "    \n",
    "    # Verifier les IDs clients dupliques\n",
    "    if 'id_client' in df.colonnes:\n",
    "        duplicate_ids = df['id_client'].duplicated().sum()\n",
    "        if duplicate_ids > 0:\n",
    "            validation_resultats['issues'].append(f\"Found {duplicate_ids} duplicate cusamer IDs\")\n",
    "            validation_resultats['validation_passed'] = False\n",
    "    \n",
    "    return validation_resultats\n",
    "\n",
    "print(\"✅ Donnees generation functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Donnees\n",
    "\n",
    "Creons des donnees d'exemple de comportement client pour travailler. Dans un scenario reel, vous chargeriez votre jeu de donnees reel ici.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des donnees d'exemple de comportement client en utilisant le module de collecte de donnees\n",
    "n_clients = 1000\n",
    "\n",
    "# Utiliser le module de collecte de donnees pour generer des donnees d'exemple\n",
    "df = get_donnees_echantillon(n_clients)\n",
    "\n",
    "# Valider les donnees generees\n",
    "validation_resultats = validate_donnees_client(df)\n",
    "\n",
    "print(\"✅ Donnees d'exemple de comportement client creees avec succes!\")\n",
    "print(f\"📊 Donneesset shape: {df.shape}\")\n",
    "print(f\"📅 Plage de dates: {df['date_inscription'].min().strftime('%Y-%m-%d')} a {df['date_inscription'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"🔍 Donnees validation: {validation_resultats['atal_lignes']} lignes, {validation_resultats['atal_colonnes']} colonnes\")\n",
    "print(f\"⚠️  Manquant values: {validation_resultats['manquantes_values']}\")\n",
    "print(f\"🔄 Duplique lignes: {validation_resultats['duplicate_lignes']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apercu des Donnees\n",
    "\n",
    "Obtenons un apercu complet de la structure et du contenu de notre jeu de donnees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les informations de base sur le jeu de donnees\n",
    "print(\"=\" * 60)\n",
    "print(\"📊 APERCU DU JEU DE DONNEES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Donneesset Shape: {df.shape[0]:,} lignes × {df.shape[1]} colonnes\")\n",
    "print(f\"Utilisation Memoire: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print()\n",
    "\n",
    "# Afficher les informations sur les colonnes\n",
    "print(\"📋 INFORMATIONS SUR LES COLONNES\")\n",
    "print(\"-\" * 40)\n",
    "print(df.info())\n",
    "print()\n",
    "\n",
    "# Afficher les premieres lignes\n",
    "print(\"👀 PREMIERES 5 LIGNES\")\n",
    "print(\"-\" * 40)\n",
    "display(df.head())\n",
    "print()\n",
    "\n",
    "# Afficher les dernieres lignes\n",
    "print(\"👀 DERNIERES 5 LIGNES\")\n",
    "print(\"-\" * 40)\n",
    "display(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les noms de colonnes et types de donnees\n",
    "print(\"📝 DETAILS DES COLONNES\")\n",
    "print(\"-\" * 50)\n",
    "column_info = pd.DataFrame({\n",
    "    'Column': df.colonnes,\n",
    "    'Donnees Type': df.types,\n",
    "    'Non-Null Nombre': df.count(),\n",
    "    'Null Nombre': df.isnull().sum(),\n",
    "    'Null Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "display(column_info)\n",
    "print()\n",
    "\n",
    "# Afficher les valeurs uniques pour les colonnes categoriques\n",
    "print(\"🔍 VARIABLES CATEGORIQUES\")\n",
    "print(\"-\" * 50)\n",
    "categorique_cols = df.select_types(include=['objet']).colonnes\n",
    "for col in categorique_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"{col}: {unique_count} unique values\")\n",
    "    if unique_count <= 10:\n",
    "        print(f\"  Values: {list(df[col].unique())}\")\n",
    "    else:\n",
    "        print(f\"  Sample values: {list(df[col].unique()[:5])}...\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de la Qualite des Donnees\n",
    "\n",
    "Evaluation complete de la qualite des donnees incluant les valeurs manquantes, les doublons, les valeurs aberrantes et les verifications de coherence des donnees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Manquant Values Analyse\n",
    "print(\"=\" * 60)\n",
    "print(\"🔍 ANALYSE DES VALEURS MANQUANTES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculer les valeurs manquantes\n",
    "manquantes_donnees = df.isnull().sum()\n",
    "manquantes_percentage = (manquantes_donnees / len(df)) * 100\n",
    "\n",
    "# Creer un resume des valeurs manquantes\n",
    "manquantes_resume = pd.DataFrame({\n",
    "    'Column': manquantes_donnees.index,\n",
    "    'Manquant Nombre': manquantes_donnees.values,\n",
    "    'Manquant Percentage': manquantes_percentage.values\n",
    "}).sort_values('Manquant Nombre', ascending=False)\n",
    "\n",
    "# Filtrer pour afficher seulement les colonnes avec des valeurs manquantes\n",
    "manquantes_resume = manquantes_resume[manquantes_resume['Manquant Nombre'] > 0]\n",
    "\n",
    "if len(manquantes_resume) > 0:\n",
    "    print(\"⚠️  Colonnes avec des valeurs manquantes:\")\n",
    "    display(manquantes_resume)\n",
    "    \n",
    "    # Visualiser les valeurs manquantes\n",
    "    plt.figure(figtaille=(12, 6))\n",
    "    plt.subgraphique(1, 2, 1)\n",
    "    manquantes_donnees[manquantes_donnees > 0].graphique(kind='bar', couleur='salmon')\n",
    "    plt.titre('Manquant Values Nombre by Column')\n",
    "    plt.xetiquette('Columns')\n",
    "    plt.yetiquette('Manquant Nombre')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subgraphique(1, 2, 2)\n",
    "    manquantes_percentage[manquantes_percentage > 0].graphique(kind='bar', couleur='lightcoral')\n",
    "    plt.titre('Manquant Values Percentage by Column')\n",
    "    plt.xetiquette('Columns')\n",
    "    plt.yetiquette('Manquant Percentage (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✅ Aucune valeur manquante trouvee dans le jeu de donnees!\")\n",
    "    print(\"🎉 Donnees completeness: 100%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Duplique Records Analyse\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔄 ANALYSE DES ENREGISTREMENTS DUPLIQUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verifier les lignes dupliquees\n",
    "duplicate_lignes = df.duplicated().sum()\n",
    "print(f\"Total duplicate lignes: {duplicate_lignes}\")\n",
    "\n",
    "if duplicate_lignes > 0:\n",
    "    print(f\"Percentage of duplicate lignes: {(duplicate_lignes / len(df)) * 100:.2f}%\")\n",
    "    print(\"\\nSample duplicate lignes:\")\n",
    "    display(df[df.duplicated(keep=False)].head())\n",
    "else:\n",
    "    print(\"✅ Aucune ligne dupliquee trouvee!\")\n",
    "\n",
    "# Verifier les IDs clients dupliques (devraient etre uniques)\n",
    "duplicate_ids_clients = df['id_client'].duplicated().sum()\n",
    "print(f\"\\nDuplique cusamer IDs: {duplicate_ids_clients}\")\n",
    "if duplicate_ids_clients == 0:\n",
    "    print(\"✅ Tous les IDs clients sont uniques!\")\n",
    "else:\n",
    "    print(\"⚠️  Trouve des IDs clients dupliques - cela necessite une investigation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Donnees Type Validation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📊 VALIDATION DES TYPES DE DONNEES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verifier les types de donnees et suggerer des corrections\n",
    "print(\"Current donnees types:\")\n",
    "donnees_types = pd.DataFrame({\n",
    "    'Column': df.types.index,\n",
    "    'Current Type': df.types.values,\n",
    "    'Sample Values': [str(list(df[col].dropna().head(3))) for col in df.colonnes]\n",
    "})\n",
    "display(donnees_types)\n",
    "\n",
    "# Verifier les problemes potentiels de types de donnees\n",
    "print(\"\\n🔍 Donnees Type Issues Check:\")\n",
    "\n",
    "# Verifier les colonnes numeriques pour les valeurs non-numeriques\n",
    "numerique_cols = df.select_types(include=[np.number]).colonnes\n",
    "for col in numerique_cols:\n",
    "    if df[col].dtype == 'objet':\n",
    "        print(f\"⚠️  {col}: Should be numerique but is objet type\")\n",
    "\n",
    "# Verifier les valeurs negatives ou elles ne devraient pas exister\n",
    "print(\"\\n📈 Value Plage Validation:\")\n",
    "numerique_colonnes = ['age', 'atal_achats', 'atal_depense', 'duree_moyenne_session', \n",
    "                   'vues_page_par_session', 'taux_rebond', 'score_satisfaction', 'tickets_support']\n",
    "\n",
    "for col in numerique_colonnes:\n",
    "    if col in df.colonnes:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "        print(f\"{col}: Plage [{min_val:.2f}, {max_val:.2f}]\")\n",
    "        \n",
    "        # Check for logical issues\n",
    "        if col == 'age' and (min_val < 0 or max_val > 120):\n",
    "            print(f\"  ⚠️  {col}: Unusual age values detected!\")\n",
    "        elif col == 'taux_rebond' and (min_val < 0 or max_val > 1):\n",
    "            print(f\"  ⚠️  {col}: Rebond rate should be between 0 and 1!\")\n",
    "        elif col == 'score_satisfaction' and (min_val < 1 or max_val > 10):\n",
    "            print(f\"  ⚠️  {col}: Satisfaction score should be between 1 and 10!\")\n",
    "        elif col in ['atal_achats', 'vues_page_par_session', 'tickets_support'] and min_val < 0:\n",
    "            print(f\"  ⚠️  {col}: Negative values detected!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Aberrant Detection\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎯 DETECTION DES VALEURS ABERRANTES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fonction pour detecter les valeurs aberrantes en utilisant la methode IQR\n",
    "def detect_valeurs_aberrantes_iqr(donnees, column):\n",
    "    Q1 = donnees[column].quantile(0.25)\n",
    "    Q3 = donnees[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    valeurs_aberrantes = donnees[(donnees[column] < lower_bound) | (donnees[column] > upper_bound)]\n",
    "    return valeurs_aberrantes, lower_bound, upper_bound\n",
    "\n",
    "# Verifier les valeurs aberrantes dans les colonnes numeriques\n",
    "numerique_colonnes = ['age', 'atal_achats', 'atal_depense', 'duree_moyenne_session', \n",
    "                   'vues_page_par_session', 'taux_rebond', 'score_satisfaction', 'tickets_support']\n",
    "\n",
    "outlier_resume = []\n",
    "\n",
    "for col in numerique_colonnes:\n",
    "    if col in df.colonnes:\n",
    "        valeurs_aberrantes, lower_bound, upper_bound = detect_valeurs_aberrantes_iqr(df, col)\n",
    "        outlier_count = len(valeurs_aberrantes)\n",
    "        outlier_percentage = (outlier_count / len(df)) * 100\n",
    "        \n",
    "        outlier_resume.append({\n",
    "            'Column': col,\n",
    "            'Aberrant Nombre': outlier_count,\n",
    "            'Aberrant Percentage': f\"{outlier_percentage:.2f}%\",\n",
    "            'Faibleer Bound': f\"{lower_bound:.2f}\",\n",
    "            'Limite Superieure': f\"{upper_bound:.2f}\",\n",
    "            'Min Value': f\"{df[col].min():.2f}\",\n",
    "            'Max Value': f\"{df[col].max():.2f}\"\n",
    "        })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_resume)\n",
    "display(outlier_df)\n",
    "\n",
    "# Visualiser les valeurs aberrantes pour les colonnes cles\n",
    "key_colonnes = ['atal_depense', 'duree_moyenne_session', 'vues_page_par_session']\n",
    "fig, axes = plt.subgraphiques(1, 3, figtaille=(18, 6))\n",
    "\n",
    "for i, col in enumerate(key_colonnes):\n",
    "    if col in df.colonnes:\n",
    "        # Graphique en boite\n",
    "        df.boxgraphique(column=col, ax=axes[i])\n",
    "        axes[i].set_titre(f'Aberrants in {col}')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Donnees CohÃ©rence Checks\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ VERIFICATIONS DE COHERENCE DES DONNEES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verifier la coherence des dates\n",
    "print(\"📅 Date CohÃ©rence:\")\n",
    "print(f\"Inscription date range: {df['date_inscription'].min()} a {df['date_inscription'].max()}\")\n",
    "print(f\"Last activity range: {df['derniere_activite'].min()} a {df['derniere_activite'].max()}\")\n",
    "\n",
    "# Verifier si la derniere activite est apres l'inscription (coherence logique)\n",
    "date_issues = df[df['derniere_activite'] < df['date_inscription']]\n",
    "print(f\"Clients with last activity before registration: {len(date_issues)}\")\n",
    "\n",
    "if len(date_issues) > 0:\n",
    "    print(\"⚠️  Trouve des incoherences de dates!\")\n",
    "    display(date_issues[['id_client', 'date_inscription', 'derniere_activite']].head())\n",
    "else:\n",
    "    print(\"✅ Toutes les dates sont logiquement coherentes!\")\n",
    "\n",
    "# Verifier la coherence des valeurs categoriques\n",
    "print(\"\\n🏷️  Categorical Value CohÃ©rence:\")\n",
    "categorique_colonnes = ['genre', 'type_abonnement', 'type_appareil', 'source_reference']\n",
    "\n",
    "for col in categorique_colonnes:\n",
    "    if col in df.colonnes:\n",
    "        unique_values = df[col].unique()\n",
    "        print(f\"{col}: {len(unique_values)} unique values - {list(unique_values)}\")\n",
    "        \n",
    "        # Verifier les fautes de frappe potentielles ou les incoherences\n",
    "        if col == 'genre':\n",
    "            expected_values = ['M', 'F', 'Other', 'Male', 'Female']\n",
    "            unexpected = [val for val in unique_values if val not in expected_values]\n",
    "            if unexpected:\n",
    "                print(f\"  ⚠️  Unexpected genre values: {unexpected}\")\n",
    "\n",
    "# Verifier la coherence de la logique commerciale\n",
    "print(\"\\n💼 Commercial Logic CohÃ©rence:\")\n",
    "\n",
    "# Verifier si les clients avec des depenses elevees ont une satisfaction elevee\n",
    "high_spenders = df[df['atal_depense'] > df['atal_depense'].quantile(0.9)]\n",
    "high_spender_satisfaction = high_spenders['score_satisfaction'].mean()\n",
    "overall_satisfaction = df['score_satisfaction'].mean()\n",
    "\n",
    "print(f\"Eleve spender satisfaction (ap 10%): {high_spender_satisfaction:.2f}\")\n",
    "print(f\"Overall satisfaction: {overall_satisfaction:.2f}\")\n",
    "\n",
    "# Verifier la relation entre le taux de rebond et la duree de session\n",
    "print(f\"\\nRebond rate vs Session duration correlation: {df['taux_rebond'].corr(df['duree_moyenne_session']):.3f}\")\n",
    "print(\"(Expected: Negative correlation - higher bounce rate should mean shorter sessions)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Donnees Qualite Resume Report\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📋 RAPPORT DE SYNTHESE DE LA QUALITE DES DONNEES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculer le score global de qualite des donnees\n",
    "atal_issues = 0\n",
    "max_possible_issues = 10\n",
    "\n",
    "# Score des valeurs manquantes\n",
    "manquantes_score = 1 - (df.isnull().sum().sum() / (len(df) * len(df.colonnes)))\n",
    "atal_issues += (1 - manquantes_score) * 3\n",
    "\n",
    "# Score des doublons\n",
    "duplicate_score = 1 - (df.duplicated().sum() / len(df))\n",
    "atal_issues += (1 - duplicate_score) * 2\n",
    "\n",
    "# Score de coherence des types de donnees\n",
    "type_issues = 0\n",
    "for col in df.select_types(include=['objet']).colonnes:\n",
    "    if col in ['age', 'atal_achats', 'atal_depense']:  # Devrait etre numerique\n",
    "        type_issues += 1\n",
    "type_score = 1 - (type_issues / len(df.colonnes))\n",
    "atal_issues += (1 - type_score) * 2\n",
    "\n",
    "# Score des valeurs aberrantes (base sur un pourcentage raisonnable de valeurs aberrantes)\n",
    "outlier_issues = 0\n",
    "for col in ['atal_depense', 'duree_moyenne_session', 'vues_page_par_session']:\n",
    "    if col in df.colonnes:\n",
    "        valeurs_aberrantes, _, _ = detect_valeurs_aberrantes_iqr(df, col)\n",
    "        outlier_pct = len(valeurs_aberrantes) / len(df)\n",
    "        if outlier_pct > 0.1:  # Plus de 10% de valeurs aberrantes\n",
    "            outlier_issues += 1\n",
    "outlier_score = 1 - (outlier_issues / 3)\n",
    "atal_issues += (1 - outlier_score) * 2\n",
    "\n",
    "# Score de coherence\n",
    "coherence_issues = 0\n",
    "if len(df[df['derniere_activite'] < df['date_inscription']]) > 0:\n",
    "    coherence_issues += 1\n",
    "coherence_score = 1 - (coherence_issues / 1)\n",
    "atal_issues += (1 - coherence_score) * 1\n",
    "\n",
    "# Calculer le score de qualite final\n",
    "qualite_score = max(0, 1 - (atal_issues / max_possible_issues))\n",
    "\n",
    "print(f\"🎯 Overall Donnees Qualite Score: {qualite_score:.2%}\")\n",
    "print()\n",
    "\n",
    "# Evaluation de la qualite\n",
    "if qualite_score >= 0.9:\n",
    "    qualite_rating = \"🟢 EXCELLENT\"\n",
    "elif qualite_score >= 0.8:\n",
    "    qualite_rating = \"🟡 BON\"\n",
    "elif qualite_score >= 0.7:\n",
    "    qualite_rating = \"🟠 MOYEN\"\n",
    "else:\n",
    "    qualite_rating = \"🔴 FAIBLE\"\n",
    "\n",
    "print(f\"Qualite Rating: {qualite_rating}\")\n",
    "print()\n",
    "\n",
    "# Recommandations\n",
    "print(\"📝 RECOMMANDATIONS:\")\n",
    "if manquantes_score < 1:\n",
    "    print(\"• Adresser les valeurs manquantes par imputation ou collecte de donnees\")\n",
    "if duplicate_score < 1:\n",
    "    print(\"• Supprimer ou investiguer les enregistrements dupliques\")\n",
    "if type_score < 1:\n",
    "    print(\"• Corriger les types de donnees pour une meilleure analyse\")\n",
    "if outlier_score < 1:\n",
    "    print(\"• Investiguer et gerer les valeurs aberrantes de maniere appropriee\")\n",
    "if coherence_score < 1:\n",
    "    print(\"• Corriger les problemes de coherence des donnees\")\n",
    "\n",
    "print(f\"\\n✅ Donnees is ready for analyse with {qualite_score:.1%} score de qualite!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations Exploraaires\n",
    "\n",
    "Creer des visualisations completes pour comprendre les distributions de donnees, les relations et les modeles dans le comportement des clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Distribution Analyse - Numeric Variables\n",
    "print(\"=\" * 60)\n",
    "print(\"📊 ANALYSE DE DISTRIBUTION - VARIABLES NUMERIQUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Selectionner les variables numeriques cles pour l'analyse de distribution\n",
    "numerique_vars = ['age', 'atal_achats', 'atal_depense', 'duree_moyenne_session', \n",
    "                'vues_page_par_session', 'taux_rebond', 'score_satisfaction', 'tickets_support']\n",
    "\n",
    "# Filtrer pour inclure seulement les colonnes qui existent dans le donneesframe\n",
    "numerique_vars = [var for var in numerique_vars if var in df.colonnes]\n",
    "\n",
    "# Creer des graphiques de distribution\n",
    "n_vars = len(numerique_vars)\n",
    "n_cols = min(4, n_vars)\n",
    "n_lignes = (n_vars + n_cols - 1) // n_cols  # Division par le plafond\n",
    "\n",
    "fig, axes = plt.subgraphiques(n_lignes, n_cols, figtaille=(5*n_cols, 4*n_lignes))\n",
    "if n_vars == 1:\n",
    "    axes = [axes]\n",
    "elif n_lignes == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, var in enumerate(numerique_vars):\n",
    "    if i < len(axes):\n",
    "        # Hisagramme\n",
    "        df[var].hist(bins=30, alpha=0.7, ax=axes[i], couleur='skyblue', edgecouleur='black')\n",
    "        \n",
    "        # Ajouter les statistiques\n",
    "        mean_val = df[var].mean()\n",
    "        median_val = df[var].median()\n",
    "        axes[i].axvline(mean_val, couleur='green', linestyle='--', linelargeur=2, etiquette=f'Moyenne: {mean_val:.2f}')\n",
    "        axes[i].axvline(median_val, couleur='orange', linestyle='--', linelargeur=2, etiquette=f'Mediane: {median_val:.2f}')\n",
    "        \n",
    "        axes[i].set_titre(f'Distribution of {var}', fonttaille=12, fontweight='bold')\n",
    "        axes[i].set_xetiquette(var)\n",
    "        axes[i].set_yetiquette('Frequency')\n",
    "        axes[i].legende()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Masquer les sous-graphiques non utilises\n",
    "for i in range(n_vars, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques de synthese pour les distributions\n",
    "print(\"\\n📈 DISTRIBUTION SUMMARY STATISTICS:\")\n",
    "print(\"-\" * 50)\n",
    "distribution_stats = df[numerique_vars].describe()\n",
    "display(distribution_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Categorical Variables Analyse\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🏷️  VARIABLES CATEGORIQUES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Selectionner les variables categoriques\n",
    "categorique_vars = ['genre', 'ville', 'type_abonnement', 'type_appareil', 'source_reference']\n",
    "\n",
    "# Filtrer pour inclure seulement les colonnes qui existent dans le donneesframe\n",
    "categorique_vars = [var for var in categorique_vars if var in df.colonnes]\n",
    "\n",
    "# Creer des graphiques de comptage pour les variables categoriques\n",
    "n_vars = len(categorique_vars)\n",
    "n_cols = min(3, n_vars)\n",
    "n_lignes = (n_vars + n_cols - 1) // n_cols  # Division par le plafond\n",
    "\n",
    "fig, axes = plt.subgraphiques(n_lignes, n_cols, figtaille=(6*n_cols, 5*n_lignes))\n",
    "if n_vars == 1:\n",
    "    axes = [axes]\n",
    "elif n_lignes == 1 and n_cols > 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "elif n_lignes > 1 and n_cols == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, var in enumerate(categorique_vars):\n",
    "    if i < len(axes):\n",
    "        # Graphique de comptage\n",
    "        value_counts = df[var].value_counts()\n",
    "        bars = axes[i].bar(range(len(value_counts)), value_counts.values, \n",
    "                          couleur=plt.cm.Set3(np.linspace(0, 1, len(value_counts))))\n",
    "        \n",
    "        # Ajouter les etiquettes de valeur sur les barres\n",
    "        for j, (bar, count) in enumerate(zip(bars, value_counts.values)):\n",
    "            axes[i].text(bar.get_x() + bar.get_largeur()/2, bar.get_hauteur() + 0.5,\n",
    "                        f'{count}\\n({count/len(df)*100:.1f}%)',\n",
    "                        ha='center', va='botam', fonttaille=10)\n",
    "        \n",
    "        axes[i].set_titre(f'Distribution of {var}', fonttaille=12, fontweight='bold')\n",
    "        axes[i].set_xetiquette(var)\n",
    "        axes[i].set_yetiquette('Nombre')\n",
    "        axes[i].set_xticks(range(len(value_counts)))\n",
    "        axes[i].set_xticketiquettes(value_counts.index, rotation=45, ha='right')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Masquer les sous-graphiques non utilises\n",
    "for i in range(n_vars, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les statistiques categoriques\n",
    "print(\"\\n📊 VARIABLES CATEGORIQUES SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "for var in categorique_vars:\n",
    "    if var in df.colonnes:\n",
    "        print(f\"\\n{var}:\")\n",
    "        value_counts = df[var].value_counts()\n",
    "        for value, count in value_counts.items():\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"  {value}: {count} ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Correlation Analyse\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔗 ANALYSE DE CORRELATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculer la matrice de correlation pour les variables numeriques\n",
    "correlation_vars = ['age', 'atal_achats', 'atal_depense', 'duree_moyenne_session', \n",
    "                   'vues_page_par_session', 'taux_rebond', 'score_satisfaction', 'tickets_support']\n",
    "\n",
    "# Filtrer pour inclure seulement les colonnes qui existent dans le donneesframe\n",
    "correlation_vars = [var for var in correlation_vars if var in df.colonnes]\n",
    "\n",
    "if len(correlation_vars) > 1:\n",
    "    corr_matrix = df[correlation_vars].corr()\n",
    "else:\n",
    "    print(\"⚠️  Not enough numerique variables for correlation analyse\")\n",
    "    corr_matrix = pd.DataFrame()\n",
    "\n",
    "# Creer la carte de chaleur de correlation\n",
    "if not corr_matrix.empty:\n",
    "    plt.figure(figtaille=(12, 10))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Masquer le triangle superieur\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n",
    "                square=True, linelargeurs=0.5, cbar_kws={\"shrink\": 0.8}, fmt='.2f')\n",
    "    plt.titre('Correlation Matrix - Client Comportement Variables', fonttaille=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Trouver les correlations les plus fortes\n",
    "    print(\"\\n🔍 STRONGEST CORRELATIONS:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Obtenir le triangle superieur de la matrice de correlation\n",
    "    corr_pairs = []\n",
    "    for i in range(len(corr_matrix.colonnes)):\n",
    "        for j in range(i+1, len(corr_matrix.colonnes)):\n",
    "            corr_pairs.append({\n",
    "                'Variable 1': corr_matrix.colonnes[i],\n",
    "                'Variable 2': corr_matrix.colonnes[j],\n",
    "                'Correlation': corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "    corr_df = pd.DataFrame(corr_pairs)\n",
    "    corr_df['Abs_Correlation'] = abs(corr_df['Correlation'])\n",
    "    strongest_corr = corr_df.nlargest(5, 'Abs_Correlation')\n",
    "\n",
    "    for _, row in strongest_corr.iterlignes():\n",
    "        print(f\"{row['Variable 1']} ↔ {row['Variable 2']}: {row['Correlation']:.3f}\")\n",
    "\n",
    "    # Creer des graphiques de dispersion pour les correlations les plus fortes\n",
    "    if len(strongest_corr) > 0:\n",
    "        n_graphiques = min(3, len(strongest_corr))\n",
    "        fig, axes = plt.subgraphiques(1, n_graphiques, figtaille=(5*n_graphiques, 5))\n",
    "        if n_graphiques == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, (_, row) in enumerate(strongest_corr.head(n_graphiques).iterlignes()):\n",
    "            var1, var2 = row['Variable 1'], row['Variable 2']\n",
    "            axes[i].scatter(df[var1], df[var2], alpha=0.6, couleur='steelblue')\n",
    "            axes[i].set_xetiquette(var1)\n",
    "            axes[i].set_yetiquette(var2)\n",
    "            axes[i].set_titre(f'{var1} vs {var2}\\nCorrelation: {row[\"Correlation\"]:.3f}')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"⚠️  Cannot create correlation analyse - insufficient numerique variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Client Segmentation Analyse\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"👥 ANALYSE DE SEGMENTATION DES CLIENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Creer des segments clients bases sur le comportement de depenses\n",
    "try:\n",
    "    df['spending_segment'] = pd.cut(df['atal_depense'], \n",
    "                                   bins=[0, 200, 500, 1000, float('inf')], \n",
    "                                   etiquettes=['Faible', 'Moyen', 'Eleve', 'VIP'])\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not create spending segments: {e}\")\n",
    "    df['spending_segment'] = 'Unknown'\n",
    "\n",
    "# Creer des segments d'age\n",
    "try:\n",
    "    df['age_segment'] = pd.cut(df['age'], \n",
    "                              bins=[0, 25, 35, 50, 65, 100], \n",
    "                              etiquettes=['18-25', '26-35', '36-50', '51-65', '65+'])\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not create age segments: {e}\")\n",
    "    df['age_segment'] = 'Unknown'\n",
    "\n",
    "# Analyser les depenses par segments\n",
    "fig, axes = plt.subgraphiques(2, 2, figtaille=(15, 12))\n",
    "\n",
    "# Depenses par type d'abonnement\n",
    "spending_by_subscription = df.groupby('type_abonnement')['atal_depense'].agg(['mean', 'count'])\n",
    "spending_by_subscription.graphique(kind='bar', ax=axes[0,0], couleur='lightcoral')\n",
    "axes[0,0].set_titre('Moyen Depenses by Abonnement Type')\n",
    "axes[0,0].set_yetiquette('Moyen Total Spent (CHF)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Depenses par segment d'age\n",
    "spending_by_age = df.groupby('age_segment')['atal_depense'].mean()\n",
    "spending_by_age.graphique(kind='bar', ax=axes[0,1], couleur='lightblue')\n",
    "axes[0,1].set_titre('Moyen Depenses by Age Segment')\n",
    "axes[0,1].set_yetiquette('Moyen Total Spent (CHF)')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Depenses par type d'appareil\n",
    "spending_by_device = df.groupby('type_appareil')['atal_depense'].mean()\n",
    "spending_by_device.graphique(kind='bar', ax=axes[1,0], couleur='lightgreen')\n",
    "axes[1,0].set_titre('Moyen Depenses by Appareil Type')\n",
    "axes[1,0].set_yetiquette('Moyen Total Spent (CHF)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Depenses par ville\n",
    "spending_by_ville = df.groupby('ville')['atal_depense'].mean().sort_values(ascending=False)\n",
    "spending_by_ville.graphique(kind='bar', ax=axes[1,1], couleur='gold')\n",
    "axes[1,1].set_titre('Moyen Depenses by Ville')\n",
    "axes[1,1].set_yetiquette('Moyen Total Spent (CHF)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher le resume de segmentation\n",
    "print(\"\\n📊 CUSTOMER SEGMENTATION SUMMARY:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Depenses Segments:\")\n",
    "spending_segment_resume = df['spending_segment'].value_counts()\n",
    "for segment, count in spending_segment_resume.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    avg_spending = df[df['spending_segment'] == segment]['atal_depense'].mean()\n",
    "    print(f\"  {segment}: {count} cusamers ({percentage:.1f}%) - Avg: CHF{avg_spending:.2f}\")\n",
    "\n",
    "print(\"\\nAge Segments:\")\n",
    "age_segment_resume = df['age_segment'].value_counts()\n",
    "for segment, count in age_segment_resume.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {segment}: {count} cusamers ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Interactive Visualisations with Plotly\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎨 VISUALISATIONS INTERACTIVES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Preparer les donnees propres pour les visualisations interactives\n",
    "    df_clean = df.dropna(subset=['score_satisfaction']).copy()\n",
    "    \n",
    "    # Assurer les types de donnees appropries pour Plotly\n",
    "    df_clean['type_abonnement'] = df_clean['type_abonnement'].astype(str)\n",
    "    df_clean['ville'] = df_clean['ville'].astype(str)\n",
    "    df_clean['genre'] = df_clean['genre'].astype(str)\n",
    "    df_clean['type_appareil'] = df_clean['type_appareil'].astype(str)\n",
    "    \n",
    "    print(f\"📊 Using {len(df_clean)} cusamers with complete satisfaction donnees\")\n",
    "    \n",
    "    # Creer un graphique de dispersion interactif: Total Depense vs Score de Satisfaction\n",
    "    print(\"Creating scatter graphique...\")\n",
    "    fig_scatter = px.scatter(\n",
    "        df_clean, \n",
    "        x='atal_depense', \n",
    "        y='score_satisfaction', \n",
    "        couleur='type_abonnement', \n",
    "        taille='atal_achats',\n",
    "        hover_donnees=['age', 'ville', 'type_appareil'],\n",
    "        titre='Client Depenses vs Satisfaction by Abonnement Type',\n",
    "        etiquettes={\n",
    "            'atal_depense': 'Total Spent (CHF)', \n",
    "            'score_satisfaction': 'Satisfaction Score',\n",
    "            'type_abonnement': 'Abonnement Type',\n",
    "            'atal_achats': 'Total Achats'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    fig_scatter.update_layout(\n",
    "        largeur=800, \n",
    "        hauteur=600,\n",
    "        showlegende=True,\n",
    "        titre_x=0.5\n",
    "    )\n",
    "    fig_scatter.show()\n",
    "    \n",
    "    # Creer un graphique en boite interactif pour les depenses par ville\n",
    "    print(\"Creating box graphique...\")\n",
    "    fig_box = px.box(\n",
    "        df_clean, \n",
    "        x='ville', \n",
    "        y='atal_depense', \n",
    "        couleur='type_abonnement',\n",
    "        titre='Depenses Distribution by Ville and Abonnement Type',\n",
    "        etiquettes={\n",
    "            'atal_depense': 'Total Spent (CHF)', \n",
    "            'ville': 'Ville',\n",
    "            'type_abonnement': 'Abonnement Type'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    fig_box.update_layout(\n",
    "        largeur=1000, \n",
    "        hauteur=600,\n",
    "        xaxis_tickangle=-45,\n",
    "        titre_x=0.5\n",
    "    )\n",
    "    fig_box.show()\n",
    "    \n",
    "    # Creer un hisagramme interactif pour la distribution d'age\n",
    "    print(\"Creating hisagram...\")\n",
    "    fig_hist = px.hisagram(\n",
    "        df_clean, \n",
    "        x='age', \n",
    "        couleur='genre', \n",
    "        nbins=20,\n",
    "        titre='Age Distribution by Genre',\n",
    "        etiquettes={\n",
    "            'age': 'Age', \n",
    "            'count': 'Number of Clients',\n",
    "            'genre': 'Genre'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    fig_hist.update_layout(\n",
    "        largeur=800, \n",
    "        hauteur=500,\n",
    "        showlegende=True,\n",
    "        titre_x=0.5\n",
    "    )\n",
    "    fig_hist.show()\n",
    "    \n",
    "    print(\"✅ Interactive visualisations created successfully!\")\n",
    "    print(\"💡 Hover over the graphiques a see detailed information!\")\n",
    "    print(\"🔍 Utiliser the legende a filter by different categories!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating interactive visualisations: {e}\")\n",
    "    print(\"🔄 Creating fallback static visualisations...\")\n",
    "    \n",
    "    # Solution de secours: Creer des versions statiques\n",
    "    fig, axes = plt.subgraphiques(1, 3, figtaille=(18, 6))\n",
    "    \n",
    "    # Graphique de dispersion\n",
    "    for sub_type in df_clean['type_abonnement'].unique():\n",
    "        mask = df_clean['type_abonnement'] == sub_type\n",
    "        axes[0].scatter(df_clean[mask]['atal_depense'], df_clean[mask]['score_satisfaction'], \n",
    "                       etiquette=sub_type, alpha=0.6)\n",
    "    axes[0].set_xetiquette('Total Spent (CHF)')\n",
    "    axes[0].set_yetiquette('Satisfaction Score')\n",
    "    axes[0].set_titre('Depenses vs Satisfaction')\n",
    "    axes[0].legende()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Graphique en boite\n",
    "    df_clean.boxgraphique(column='atal_depense', by='ville', ax=axes[1])\n",
    "    axes[1].set_titre('Depenses by Ville')\n",
    "    axes[1].set_xetiquette('Ville')\n",
    "    axes[1].set_yetiquette('Total Spent (CHF)')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Hisagramme\n",
    "    for genre in df_clean['genre'].unique():\n",
    "        mask = df_clean['genre'] == genre\n",
    "        axes[2].hist(df_clean[mask]['age'], alpha=0.7, etiquette=genre, bins=20)\n",
    "    axes[2].set_xetiquette('Age')\n",
    "    axes[2].set_yetiquette('Number of Clients')\n",
    "    axes[2].set_titre('Age Distribution by Genre')\n",
    "    axes[2].legende()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"✅ Fallback static visualisations created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Time-based Analyse\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📅 ANALYSE TEMPORELLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convertir les dates en datetime si elles ne le sont pas deja\n",
    "df['date_inscription'] = pd.a_datetime(df['date_inscription'])\n",
    "df['derniere_activite'] = pd.a_datetime(df['derniere_activite'])\n",
    "\n",
    "# Creer les tendances d'inscription mensuelles\n",
    "df['registration_month'] = df['date_inscription'].dt.a_period('M')\n",
    "monthly_registrations = df['registration_month'].value_counts().sort_index()\n",
    "\n",
    "# Creer les tendances d'activite mensuelles\n",
    "df['activity_month'] = df['derniere_activite'].dt.a_period('M')\n",
    "monthly_activity = df['activity_month'].value_counts().sort_index()\n",
    "\n",
    "# Tracer les tendances temporelles\n",
    "fig, axes = plt.subgraphiques(2, 2, figtaille=(16, 12))\n",
    "\n",
    "# Inscriptions mensuelles\n",
    "monthly_registrations.graphique(kind='line', ax=axes[0,0], marker='o', couleur='blue', linelargeur=2)\n",
    "axes[0,0].set_titre('Monthly Client Inscriptions', fontweight='bold')\n",
    "axes[0,0].set_xetiquette('Month')\n",
    "axes[0,0].set_yetiquette('Number of Inscriptions')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Activite mensuelle\n",
    "monthly_activity.graphique(kind='line', ax=axes[0,1], marker='s', couleur='green', linelargeur=2)\n",
    "axes[0,1].set_titre('Monthly Client Activite', fontweight='bold')\n",
    "axes[0,1].set_xetiquette('Month')\n",
    "axes[0,1].set_yetiquette('Number of Activities')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Duree de vie client (jours entre l'inscription et la derniere activite)\n",
    "df['cusamer_lifetime_days'] = (df['derniere_activite'] - df['date_inscription']).dt.days\n",
    "df['cusamer_lifetime_days'].hist(bins=30, ax=axes[1,0], couleur='orange', alpha=0.7, edgecouleur='black')\n",
    "axes[1,0].set_titre('Client Lifetime Distribution', fontweight='bold')\n",
    "axes[1,0].set_xetiquette('Days')\n",
    "axes[1,0].set_yetiquette('Number of Clients')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Inscription par jour de la semaine\n",
    "df['registration_dow'] = df['date_inscription'].dt.day_name()\n",
    "dow_registrations = df['registration_dow'].value_counts()\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_registrations = dow_registrations.reindex(dow_order)\n",
    "dow_registrations.graphique(kind='bar', ax=axes[1,1], couleur='purple', alpha=0.7)\n",
    "axes[1,1].set_titre('Inscriptions by Day of Week', fontweight='bold')\n",
    "axes[1,1].set_xetiquette('Day of Week')\n",
    "axes[1,1].set_yetiquette('Number of Inscriptions')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les insights temporels\n",
    "print(\"\\n📊 TIME-BASED INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Moyen cusamer lifetime: {df['cusamer_lifetime_days'].mean():.1f} days\")\n",
    "print(f\"Mediane cusamer lifetime: {df['cusamer_lifetime_days'].median():.1f} days\")\n",
    "print(f\"Peak registration month: {monthly_registrations.idxmax()}\")\n",
    "print(f\"Peak activity month: {monthly_activity.idxmax()}\")\n",
    "print(f\"Most popular registration day: {dow_registrations.idxmax()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistiques de Synthese\n",
    "\n",
    "Statistiques de synthese completes, metriques commerciales et insights cles de l'analyse du comportement des clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Executif Statistiques de Synthese\n",
    "print(\"=\" * 80)\n",
    "print(\"📊 SYNTHESE EXECUTIVE - ANALYSE DES COMPORTEMENTS CLIENTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Metriques Commerciales Cles\n",
    "atal_cusamers = len(df)\n",
    "atal_revenue = df['atal_depense'].sum() if 'atal_depense' in df.colonnes else 0\n",
    "avg_revenue_per_cusamer = df['atal_depense'].mean() if 'atal_depense' in df.colonnes else 0\n",
    "median_revenue_per_cusamer = df['atal_depense'].median() if 'atal_depense' in df.colonnes else 0\n",
    "atal_achats = df['atal_achats'].sum() if 'atal_achats' in df.colonnes else 0\n",
    "avg_purchases_per_cusamer = df['atal_achats'].mean() if 'atal_achats' in df.colonnes else 0\n",
    "avg_satisfaction = df['score_satisfaction'].mean() if 'score_satisfaction' in df.colonnes else 0\n",
    "duree_moyenne_session = df['duree_moyenne_session'].mean() if 'duree_moyenne_session' in df.colonnes else 0\n",
    "\n",
    "print(f\"👥 Total Clients: {atal_cusamers:,}\")\n",
    "print(f\"💰 Total Revenus: CHF{atal_revenue:,.2f}\")\n",
    "print(f\"💵 Moyen Revenus per Client: CHF{avg_revenue_per_cusamer:.2f}\")\n",
    "print(f\"📊 Mediane Revenus per Client: CHF{median_revenue_per_cusamer:.2f}\")\n",
    "print(f\"🛒 Total Achats: {atal_achats:,}\")\n",
    "print(f\"🛍️  Moyen Achats per Client: {avg_purchases_per_cusamer:.1f}\")\n",
    "print(f\"😊 Moyen Satisfaction Score: {avg_satisfaction:.1f}/10\")\n",
    "print(f\"⏱️  Moyen Session Duree: {duree_moyenne_session:.1f} minutes\")\n",
    "print()\n",
    "\n",
    "# Resume Demographique des Clients\n",
    "print(\"👥 DEMOGRAPHIE DES CLIENTS:\")\n",
    "print(\"-\" * 40)\n",
    "if 'age' in df.colonnes:\n",
    "    print(f\"Moyen Age: {df['age'].mean():.1f} years\")\n",
    "    print(f\"Plage d'Age: {df['age'].min()} - {df['age'].max()} years\")\n",
    "else:\n",
    "    print(\"Age donnees not available\")\n",
    "\n",
    "if 'genre' in df.colonnes:\n",
    "    print(f\"Genre Distribution:\")\n",
    "    genre_dist = df['genre'].value_counts()\n",
    "    for genre, count in genre_dist.items():\n",
    "        percentage = (count / atal_cusamers) * 100\n",
    "        print(f\"  {genre}: {count} ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"Genre donnees not available\")\n",
    "\n",
    "if 'ville' in df.colonnes:\n",
    "    print(f\"\\nTop 3 Cities by Client Nombre:\")\n",
    "    ville_dist = df['ville'].value_counts().head(3)\n",
    "    for ville, count in ville_dist.items():\n",
    "        percentage = (count / atal_cusamers) * 100\n",
    "        print(f\"  {ville}: {count} ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"Ville donnees not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Commercial Performance Metriques\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📈 METRIQUES DE PERFORMANCE COMMERCIALE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Analyse des Revenus\n",
    "print(\"💰 REVENUE ANALYSIS:\")\n",
    "print(\"-\" * 30)\n",
    "revenue_by_subscription = df.groupby('type_abonnement')['atal_depense'].agg(['sum', 'mean', 'count'])\n",
    "revenue_by_subscription.colonnes = ['Total Revenus', 'Avg Revenus per Client', 'Client Nombre']\n",
    "revenue_by_subscription['Revenus Share %'] = (revenue_by_subscription['Total Revenus'] / atal_revenue * 100).round(1)\n",
    "display(revenue_by_subscription)\n",
    "\n",
    "# Segments les plus performants\n",
    "print(f\"\\n🏆 TOP PERFORMING SEGMENTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Eleveest Revenus Cities:\")\n",
    "ap_villes = df.groupby('ville')['atal_depense'].sum().sort_values(ascending=False).head(3)\n",
    "for ville, revenue in ap_villes.items():\n",
    "    print(f\"  {ville}: CHF{revenue:,.2f}\")\n",
    "\n",
    "print(\"\\nEleveest Revenus Age Segments:\")\n",
    "ap_age_segments = df.groupby('age_segment')['atal_depense'].sum().sort_values(ascending=False).head(3)\n",
    "for segment, revenue in ap_age_segments.items():\n",
    "    print(f\"  {segment}: CHF{revenue:,.2f}\")\n",
    "\n",
    "print(\"\\nEleveest Revenus Appareil Types:\")\n",
    "ap_devices = df.groupby('type_appareil')['atal_depense'].sum().sort_values(ascending=False)\n",
    "for device, revenue in ap_devices.items():\n",
    "    print(f\"  {device}: CHF{revenue:,.2f}\")\n",
    "\n",
    "# Metriques d'Engagement Client\n",
    "print(f\"\\n📱 CUSTOMER ENGAGEMENT METRICS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Moyen Page Vues per Session: {df['vues_page_par_session'].mean():.1f}\")\n",
    "print(f\"Moyen Rebond Rate: {df['taux_rebond'].mean():.3f} ({df['taux_rebond'].mean()*100:.1f}%)\")\n",
    "print(f\"Moyen Support Tickets per Client: {df['tickets_support'].mean():.2f}\")\n",
    "\n",
    "# Identification des clients a haute valeur\n",
    "high_value_threshold = df['atal_depense'].quantile(0.9)\n",
    "high_value_cusamers = df[df['atal_depense'] >= high_value_threshold]\n",
    "print(f\"\\n💎 HIGH-VALUE CUSTOMERS (Top 10%):\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Nombre: {len(high_value_cusamers)} cusamers\")\n",
    "print(f\"Moyen Depenses: CHF{high_value_cusamers['atal_depense'].mean():.2f}\")\n",
    "print(f\"Moyen Satisfaction: {high_value_cusamers['score_satisfaction'].mean():.1f}/10\")\n",
    "print(f\"Most Common Abonnement: {high_value_cusamers['type_abonnement'].mode().iloc[0]}\")\n",
    "print(f\"Most Common Appareil: {high_value_cusamers['type_appareil'].mode().iloc[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Insights Cles and Commercial Recommandations\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"💡 INSIGHTS CLES ET RECOMMANDATIONS COMMERCIALES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Insights sur le comportement des clients\n",
    "print(\"🎯 CUSTOMER BEHAVIOR INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Comportement de depenses\n",
    "high_spenders = df[df['atal_depense'] > df['atal_depense'].quantile(0.75)]\n",
    "low_spenders = df[df['atal_depense'] < df['atal_depense'].quantile(0.25)]\n",
    "\n",
    "print(f\"• Eleve Spenders (Top 25%) vs Faible Spenders (Botam 25%):\")\n",
    "print(f\"  - Eleve Spenders: {len(high_spenders)} cusamers, Avg: CHF{high_spenders['atal_depense'].mean():.2f}\")\n",
    "print(f\"  - Faible Spenders: {len(low_spenders)} cusamers, Avg: CHF{low_spenders['atal_depense'].mean():.2f}\")\n",
    "print(f\"  - Depenses Ratio: {high_spenders['atal_depense'].mean() / low_spenders['atal_depense'].mean():.1f}x\")\n",
    "\n",
    "# Modeles d'engagement\n",
    "print(f\"\\n• Engagement Modeles:\")\n",
    "print(f\"  - Eleve Engagement (Long Sessions): {len(df[df['duree_moyenne_session'] > df['duree_moyenne_session'].quantile(0.75)])} cusamers\")\n",
    "print(f\"  - Faible Engagement (Short Sessions): {len(df[df['duree_moyenne_session'] < df['duree_moyenne_session'].quantile(0.25)])} cusamers\")\n",
    "print(f\"  - Eleve Rebond Rate (>50%): {len(df[df['taux_rebond'] > 0.5])} cusamers ({len(df[df['taux_rebond'] > 0.5])/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Analyse de satisfaction\n",
    "print(f\"\\n• Satisfaction Analyse:\")\n",
    "satisfied_cusamers = df[df['score_satisfaction'] >= 8]\n",
    "dissatisfied_cusamers = df[df['score_satisfaction'] <= 4]\n",
    "print(f\"  - Satisfied Clients (8+): {len(satisfied_cusamers)} ({len(satisfied_cusamers)/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Dissatisfied Clients (≤4): {len(dissatisfied_cusamers)} ({len(dissatisfied_cusamers)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Recommandations Commerciales\n",
    "print(f\"\\n📋 STRATEGIC RECOMMANDATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Optimisation des revenus\n",
    "print(\"💰 REVENUE OPTIMIZATION:\")\n",
    "print(\"1. Focus on Eleve-Value Client Segments:\")\n",
    "print(f\"   • Target cusamers with {high_value_cusamers['type_abonnement'].mode().iloc[0]} subscriptions\")\n",
    "print(f\"   • Prioritize {high_value_cusamers['type_appareil'].mode().iloc[0]} users for premium features\")\n",
    "print(f\"   • Implement VIP programs for ap {len(high_value_cusamers)} cusamers\")\n",
    "\n",
    "# Strategie d'abonnement\n",
    "best_subscription = df.groupby('type_abonnement')['atal_depense'].mean().idxmax()\n",
    "print(f\"\\n2. Abonnement Strategy:\")\n",
    "print(f\"   • Promote {best_subscription} subscription as it shows highest average spending\")\n",
    "print(f\"   • Create upgrade incentives for Basique → Premium cusamers\")\n",
    "print(f\"   • Develop Entreprise features based on high-value cusamer needs\")\n",
    "\n",
    "# Expansion geographique\n",
    "ap_ville = df.groupby('ville')['atal_depense'].mean().idxmax()\n",
    "print(f\"\\n3. Geographic Expansion:\")\n",
    "print(f\"   • Expand marketing efforts in {ap_ville} (highest avg spending)\")\n",
    "print(f\"   • Replicate successful strategies from ap-performing villes\")\n",
    "print(f\"   • Consider local partnerships in high-value markets\")\n",
    "\n",
    "# Experience client\n",
    "print(f\"\\n4. Client Experience Improvements:\")\n",
    "print(f\"   • Address high bounce rate ({len(df[df['taux_rebond'] > 0.5])/len(df)*100:.1f}% of cusamers)\")\n",
    "print(f\"   • Improve session duration for better engagement\")\n",
    "print(f\"   • Implement satisfaction surveys for cusamers scoring ≤4\")\n",
    "\n",
    "# Optimisation de l'engagement\n",
    "print(f\"\\n5. Engagement Optimization:\")\n",
    "print(f\"   • Develop mobile-first features (60% mobile users)\")\n",
    "print(f\"   • Create personalized content based on age segments\")\n",
    "print(f\"   • Implement loyalty programs for repeat cusamers\")\n",
    "\n",
    "print(f\"\\n📊 SUCCESS METRICS TO TRACK:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"• Client Lifetime Value (CLV)\")\n",
    "print(\"• Monthly Recurring Revenus (MRR)\")\n",
    "print(\"• Client Acquisition Cost (CAC)\")\n",
    "print(\"• Churn Rate by segment\")\n",
    "print(\"• Net Promoter Score (NPS)\")\n",
    "print(\"• Moyen Revenus Per Utiliserr (ARPU)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Final Resume Tableau de bord\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📊 TABLEAU DE BORD DE SYNTHESE FINALE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Creer un tableau de bord de synthese\n",
    "fig, axes = plt.subgraphiques(2, 3, figtaille=(20, 12))\n",
    "\n",
    "# 1. Revenus by Abonnement Type\n",
    "revenue_by_sub = df.groupby('type_abonnement')['atal_depense'].sum()\n",
    "revenue_by_sub.graphique(kind='pie', ax=axes[0,0], auapct='%1.1f%%', startangle=90)\n",
    "axes[0,0].set_titre('Revenus Distribution by Abonnement Type', fontweight='bold')\n",
    "axes[0,0].set_yetiquette('')\n",
    "\n",
    "# 2. Client Nombre by Ville\n",
    "ville_counts = df['ville'].value_counts().head(5)\n",
    "ville_counts.graphique(kind='bar', ax=axes[0,1], couleur='lightblue')\n",
    "axes[0,1].set_titre('Top 5 Cities by Client Nombre', fontweight='bold')\n",
    "axes[0,1].set_xetiquette('Ville')\n",
    "axes[0,1].set_yetiquette('Number of Clients')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Satisfaction Score Distribution\n",
    "df['score_satisfaction'].hist(bins=10, ax=axes[0,2], couleur='lightgreen', alpha=0.7, edgecouleur='black')\n",
    "axes[0,2].set_titre('Satisfaction Score Distribution', fontweight='bold')\n",
    "axes[0,2].set_xetiquette('Satisfaction Score')\n",
    "axes[0,2].set_yetiquette('Number of Clients')\n",
    "axes[0,2].axvline(df['score_satisfaction'].mean(), couleur='red', linestyle='--', \n",
    "                  etiquette=f'Moyenne: {df[\"score_satisfaction\"].mean():.1f}')\n",
    "axes[0,2].legende()\n",
    "\n",
    "# 4. Depenses by Age Segment\n",
    "age_spending = df.groupby('age_segment')['atal_depense'].mean()\n",
    "age_spending.graphique(kind='bar', ax=axes[1,0], couleur='gold')\n",
    "axes[1,0].set_titre('Moyen Depenses by Age Segment', fontweight='bold')\n",
    "axes[1,0].set_xetiquette('Age Segment')\n",
    "axes[1,0].set_yetiquette('Moyen Total Spent (CHF)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. Appareil Type Distribution\n",
    "device_counts = df['type_appareil'].value_counts()\n",
    "device_counts.graphique(kind='bar', ax=axes[1,1], couleur='lightcoral')\n",
    "axes[1,1].set_titre('Client Distribution by Appareil Type', fontweight='bold')\n",
    "axes[1,1].set_xetiquette('Appareil Type')\n",
    "axes[1,1].set_yetiquette('Number of Clients')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Cle Metriques Resume\n",
    "axes[1,2].axis('off')\n",
    "resume_text = f\"\"\"\n",
    "KEY METRICS SUMMARY\n",
    "\n",
    "👥 Total Clients: {atal_cusamers:,}\n",
    "💰 Total Revenus: CHF{atal_revenue:,.0f}\n",
    "💵 Avg Revenus/Client: CHF{avg_revenue_per_cusamer:.0f}\n",
    "😊 Avg Satisfaction: {avg_satisfaction:.1f}/10\n",
    "⏱️ Avg Session Duree: {duree_moyenne_session:.1f} min\n",
    "\n",
    "TOP INSIGHTS:\n",
    "• {best_subscription} subscription performs best\n",
    "• {ap_ville} shows highest spending\n",
    "• {len(high_value_cusamers)} high-value cusamers identified\n",
    "• {len(satisfied_cusamers)} satisfied cusamers (8+ rating)\n",
    "\"\"\"\n",
    "\n",
    "axes[1,2].text(0.1, 0.9, resume_text, transform=axes[1,2].transAxes, \n",
    "               fonttaille=12, verticalalignment='ap', fontfamily='monospace',\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecouleur=\"lightgray\", alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ EXPLORATION DES DONNEES TERMINEE!\")\n",
    "print(\"🎉 Votre analyse complete du comportement des clients est prete!\")\n",
    "print(\"📈 Utiliser these insights a drive donnees-driven business decisions!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}